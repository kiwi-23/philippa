# Philippa
<p><b>An artistic exploration of a philosophical inquiry regarding the worth of a person’s life, inspecting the grounds of moral status and mapping it onto a framework where logic meets morality.</b></p>

<a href="https://mya-kiwi.com/project/philippa">visit the project</a>

<br>
<h2>Abstract</h2>

You are the driver of a trolley car that is hurtling down the track at sixty miles an hour, and you notice there are five workers working towards the end of the track. The brakes are faulty, and you feel desperate because you know that if the trolley was to crash into these people, they will surely die.

You feel helpless until you notice that there is a sidetrack off to the right, and only one worker is working on that track. Your steering wheel works, so you can turn the trolley car, if you want to, onto this sidetrack- killing the one worker, but sparing five.

<i>Which is the more ethical option?</i>

• To do nothing and kill the five workers working on the track.

• Or to steer the trolley car onto the sidetrack and kill the one individual worker.

This problem illustrates two kinds of moral reasonings- <a href="https://en.wikipedia.org/wiki/Consequentialism">Consequentialism</a> that bases the morality of an action on the consequences of the action, and <a href="https://en.wikipedia.org/wiki/Deontological_ethics">Deontology</a> that bases the morality on the nature of the action.

This thought enthused my exploration of morality, specifically into trying to evaluate the worth of a person’s life. I inspect the moral worth of beings with respect to personhood, and try to identify the grounds for the heirarchy of moral statuses assigned to different entities on the basis of rationality and sentience.

<br>
<h2>Survey</h2>

In my inquiry, <a href="https://docs.google.com/forms/d/e/1FAIpQLSelGcMKG3RO2SQF9nmVPNPvnKCHpN9_e6N-ZoyUUNCIMpvNOg/viewform">I interviewed a large number of people</a> and proposed 5 such scenarios to them, the trolley problem and four other variations. 

<ol>

<li>
You are a transplant surgeon, you have 5 patients in critical need of an organ each. One needs a liver, two need a kidney,
one a heart, another a lung. There are no donors. But there is a healthy patient in the next room. Which is the more ethical course of action?

• Use the healthy patient’s organs to save 5 lives

• Do nothing & let the 5 die</li>

<li>You are a judge, and 5 activists are threatening to kill themselves if the culprit of a certain crime is not found. The real culprit remains unknown. You can prevent the bloodshed by framing an innocent individual. Which is the more ethical course of action?

• Execute the innocent person & save 5 lives

• Do nothing & let the 5 die</li>

<li>You are a doctor, and in order to save a patient, you need to give him a massive dose of a drug that’s in short supply. A little later, 5 other patients arrive, each of whom could be saved with 1/5th of that dose. Which is the more ethical option?

• Give the dose to the 5 later patients

• Give the dose to the initial patient</li>

<li>You are a doctor, and there are 5 patients whose lives could be saved by the manufacture of a certain gas. But this leads to the release of lethal fumes into the room of another patient who, for some reason, you cannot move elsewhere. Which is the more ethical option?

• Manufacture the gas & let the 1 patient die

• Do nothing & let the 5 patients die</li></ol>

<br>
<h2>Methodology</h2>

Despite having the same consequences, 5 lives against 1, your intuition will tell you that there are more moral variables at play other than just the number of lives. 

The 5 scenarios all use different combinations of four kinds of moral variables: number, desire, intent and duty. The moral framework resembles this:

action [(<i>number</i>), (<i>desire</i>), (<i>intent</i>), (<i>duty</i>)], where

<b>number</b> = the number of lives saved by that action,

<b>desire</b> = the kind of desire that’s fulfilled by that action,

<b>intent</b> = our intention behind the action, and

<b>duty</b> = the kind of obligation we’re adhering to.

<br>
“Philippa” is a neural network that is trained on this crowdsourced data. She has learnt to make ethical choices beyond what the arithmetic scope of (5 lives > 1 life) allows. 


For a detailed reading, here is the full <a href="http://dl.dropboxusercontent.com/s/go7kfmc408d4tfi/Philippa%20-%20Research%20Paper.pdf?dl=0">research paper</a>.
